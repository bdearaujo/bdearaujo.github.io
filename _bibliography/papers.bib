---
---

@inproceedings{10.1145/3490149.3501320,
author = {Rudolph, Julius Cosmo Romeo and Holman, David and De Araujo, Bruno and Jota, Ricardo and Wigdor, Daniel and Savage, Valkyrie},
title = {Sensing Hand Interactions with Everyday Objects by Profiling Wrist Topography},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3501320},
doi = {10.1145/3490149.3501320},
abstract = {We demonstrate rich inferences about unaugmented everyday objects and hand object interactions by measuring minute skin surface deformations at the wrist using a sensing technique based on capacitance. The wristband prototype infers muscle and tendon tension, pose, and motion, which we then map to force (9 users, 13.66 +/- 9.84 N regression error on classes 0–49.1 N), grasp (9 users, 81 +/- 7 \% classification accuracy on 6 grasps), and continuous interaction (10 users, 99 +/- 1 \% discrimination accuracy between 6 interactions, 89–97 \% accuracy on 3 states within each interaction) using basic machine learning models. We wrapped these sensing capabilities into a proof-of-concept end-to-end system, Ubiquitous Controls, that enables virtual range inputs by sensing continuous interactions with unaugmented objects. Eight users leveraged our system to control UI widgets (like sliders and dials) with object interactions (like “cutting with scissors’’ and “squeezing a ball”). Finally, we discuss the implications and opportunities of using hands as a ubiquitous sensor of our surroundings.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {14},
numpages = {14},
keywords = {affordances, capacitive sensing, everyday objects, wrist topography, wristband},
location = {Daejeon, Republic of Korea},
series = {TEI '22},
selected={true},
}


@inproceedings{10.1145/3173574.3173797,
author = {Xia, Haijun and Henry Riche, Nathalie and Chevalier, Fanny and De Araujo, Bruno and Wigdor, Daniel},
title = {DataInk: Direct and Creative Data-Oriented Drawing},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173797},
doi = {10.1145/3173574.3173797},
abstract = {Creating whimsical, personal data visualizations remains a challenge due to a lack of tools that enable for creative visual expression while providing support to bind graphical content to data. Many data analysis and visualization creation tools target the quick generation of visual representations, but lack the functionality necessary for graphics design. Toolkits and charting libraries offer more expressive power, but require expert programming skills to achieve custom designs. In contrast, sketching affords fluid experimentation with visual shapes and layouts in a free-form manner, but requires one to manually draw every single data point. We aim to bridge the gap between these extremes. We propose DataInk, a system supports the creation of expressive data visualizations with rigorous direct manipulation via direct pen and touch input. Leveraging our commonly held skills, coupled with a novel graphical user interface, DataInk enables direct, fluid, and flexible authoring of creative data visualizations.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {visualization, object-oriented interaction},
location = {Montreal QC, Canada},
series = {CHI '18},
selected={true},
}

@inproceedings{10.1145/3025453.3025554,
author = {Xia, Haijun and Araujo, Bruno and Wigdor, Daniel},
title = {Collection Objects: Enabling Fluid Formation and Manipulation of Aggregate Selections},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025554},
doi = {10.1145/3025453.3025554},
abstract = {Despite the long development of Graphical User Interfaces, working with multiple graphical objects remains a challenge, due to the difficulties of forming complex selections, ambiguities of operations, and tediousness of repetitively unselect-reselect or ungroup-regroup objects. Instead of tackling them as individual problems, we attribute it to the lack of system support to the general selection-action cycles. We propose Collection Objects to not only support a single fast selection-action cycle but also allow multiple cycles to be chained together into a fluid workflow. Collection Objects unifies selection, grouping, and manipulation of aggregate selections into a single object, with which selection can be composed with various techniques, modified for later actions, grouped with objects inside still directly accessible, and quasi-moded for less context switching. We implemented Collection Object in the context of a vector drawing application with simultaneous pen and touch input. Results of an expert evaluation show that Collection Objects holds considerable promises for fluid interaction with multiple objects.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5592–5604},
numpages = {13},
keywords = {collection object, object-oriented interaction, pen and touch},
location = {Denver, Colorado, USA},
series = {CHI '17},
selected={true},
}

@inproceedings{10.1145/3025453.3025719,
author = {Sahdev, Sidharth and Forlines, Clifton and Jota, Ricardo and De Araujo, Bruno and Moseley, Braon and Deber, Jonathan and Sanders, Steven and Leigh, Darren and Wigdor, Daniel},
title = {GhostID: Enabling Non-Persistent User Differentiation in Frequency-Division Capacitive Multi-Touch Sensors},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025719},
doi = {10.1145/3025453.3025719},
abstract = {Current touch devices are adept at tracking finger touches, but cannot distinguish if multiple touches are caused by different fingers on a single hand, by fingers from both hands of a single user, or by different users. This limitation significantly reduces the possibilities for interaction techniques in touch interfaces. We present GhostID, a capacitive sensor that can differentiate the origins of multiple simultaneous touches. Our approach analyzes the signal ghosting, already present as an artifact in a frequency-division touch controller, to differentiate touches from the same hand or different hands of a single user (77\% reliability at 60 fps) or from two different users (95\% reliability at 60 fps). In addition to GhostID, we also develop a framework of user-differentiation capabilities for touch input devices, and illustrate a set of interaction techniques enabled by GhostID.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {15–27},
numpages = {13},
keywords = {capacitive touch sensor, mobility, signal processing, user differentiation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/2984511.2984590,
author = {Nancel, Mathieu and Vogel, Daniel and De Araujo, Bruno and Jota, Ricardo and Casiez, G\'{e}ry},
title = {Next-Point Prediction Metrics for Perceived Spatial Errors},
year = {2016},
isbn = {9781450341899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2984511.2984590},
doi = {10.1145/2984511.2984590},
abstract = {Touch screens have a delay between user input and corresponding visual interface feedback, called input 'latency' (or 'lag'). Visual latency is more noticeable during continuous input actions like dragging, so methods to display feedback based on the most likely path for the next few input points have been described in research papers and patents. Designing these 'next-point prediction' methods is challenging, and there have been no standard metrics to compare different approaches. We introduce metrics to quantify the probability of 7 spatial error 'side-effects' caused by next-point prediction methods. Types of side-effects are derived using a thematic analysis of comments gathered in a 12 participants study covering drawing, dragging, and panning tasks using 5 state-of-the-art next-point predictors. Using experiment logs of actual and predicted input points, we develop quantitative metrics that correlate positively with the frequency of perceived side-effects. These metrics enable practitioners to compare next-point predictors using only input logs.},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
pages = {271–285},
numpages = {15},
keywords = {lag, latency, prediction, touch input},
location = {Tokyo, Japan},
series = {UIST '16}
}

@inproceedings{10.1145/2858036.2858394,
author = {Deber, Jonathan and Araujo, Bruno and Jota, Ricardo and Forlines, Clifton and Leigh, Darren and Sanders, Steven and Wigdor, Daniel},
title = {Hammer Time! A Low-Cost, High Precision, High Accuracy Tool to Measure the Latency of Touchscreen Devices},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858394},
doi = {10.1145/2858036.2858394},
abstract = {We report on the Latency Hammer, a low-cost yet highaccuracy and high-precision automated tool that measures the interface latency of touchscreen devices. The Hammer directly measures latency by triggering a capacitive touch event on a device using an electrically actuated touch simulator, and a photo sensor to monitor the screen for a visual response. This allows us to measure the full end-toend latency of a touchscreen system exactly as it would be experienced by a user. The Hammer does not require human interaction to perform a measurement, enabling the acquisition of large datasets. We present the operating principles of the Hammer, and discuss its design and construction; full design documents are available online. We also present a series of tools and equipment that were built to assess and validate the performance of the Hammer, and demonstrate that it provides reliable latency measurements.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {2857–2868},
numpages = {12},
keywords = {multi-touch input, latency measurement, latency benchmark, input latency},
location = {San Jose, California, USA},
series = {CHI '16}
}


@inproceedings{10.1145/2858036.2858079,
author = {Henrikson, Rorik and De Araujo, Bruno and Chevalier, Fanny and Singh, Karan and Balakrishnan, Ravin},
title = {Storeoboard: Sketching Stereoscopic Storyboards},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858079},
doi = {10.1145/2858036.2858079},
abstract = {We present Storeoboard, a system for stereo-cinematic conceptualization, via storyboard sketching directly in stereo. The resurgence of stereoscopic media has motivated filmmakers to evolve a new stereo-cinematic vocabulary, as many principles for stereo 3D film are unique. Concepts like plane separation, parallax position, and depth budgets are missing from early planning due to the 2D nature of existing storyboards. Storeoboard is the first of its kind, allowing filmmakers to explore, experiment and conceptualize ideas in stereo early in the film pipeline, develop new stereo-cinematic constructs and foresee potential difficulties. Storeoboard is the design outcome of interviews and field work with directors, stereographers, and storyboard artists. We present our design guidelines and implementation of a tool combining stereo-sketching, depth manipulations and storyboard features into a coherent and novel workflow. We report on feedback from storyboard artists, industry professionals and the director of a live action, feature film on which Storeoboard was deployed.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4587–4598},
numpages = {12},
keywords = {storyboard, stereoscopic, sketching, anaglyph, 3D},
location = {San Jose, California, USA},
series = {CHI '16},
  selected={true},
}

@inproceedings{10.1145/2858036.2858075,
author = {Xia, Haijun and Araujo, Bruno and Grossman, Tovi and Wigdor, Daniel},
title = {Object-Oriented Drawing},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858075},
doi = {10.1145/2858036.2858075},
abstract = {We present Object-Oriented Drawing, which replaces most WIMP UI with Attribute Objects. Attribute Objects embody the attributes of digital content as UI objects that can be manipulated through direct touch gestures. In the paper, the fundamental UI concepts are presented, including Attribute Objects, which may be moved, cloned, linked, and freely associated with drawing objects. Other functionalities, such as attribute-level blending and undo, are also demonstrated. We developed a drawing application based on the presented concepts with simultaneous touch and pen input. An expert assessment of our application shows that direct physical manipulation of Attribute Objects enables a user to quickly perform interactions which were previously tedious, or even impossible, with a coherent and consistent interaction experience throughout the entire interface.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4610–4621},
numpages = {12},
keywords = {pen and touch input, object-oriented, attribute object},
location = {San Jose, California, USA},
series = {CHI '16},
  selected={true},
}

@inproceedings{10.1145/2839462.2839484,
author = {Araujo, Bruno and Jota, Ricardo and Perumal, Varun and Yao, Jia Xian and Singh, Karan and Wigdor, Daniel},
title = {Snake Charmer: Physically Enabling Virtual Objects},
year = {2016},
isbn = {9781450335829},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2839462.2839484},
doi = {10.1145/2839462.2839484},
abstract = {Augmented and virtual reality have the potential of being indistinguishable from the real world. Holographic displays, including head mounted units, support this vision by creating rich stereoscopic scenes, with objects that appear to float in thin air - often within arm's reach. However, one has but to reach out and grasp nothing but air to destroy the suspension of disbelief. Snake-charmer is an attempt to provide physical form to virtual objects by revisiting the concept of Robotic Graphics or Encountered-type Haptic interfaces with current commodity hardware. By means of a robotic arm, Snake-charmer brings physicality to a virtual scene and explores what it means to truly interact with an object. We go beyond texture and position simulation and explore what it means to have a physical presence inside a virtual scene. We demonstrate how to render surface characteristics beyond texture and position, including temperature; how to physically move objects; and how objects can physically interact with the user's hand. We analyze our implementation, present the performance characteristics, and provide guidance for the construction of future physical renderers.},
booktitle = {Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction},
pages = {218–226},
numpages = {9},
location = {Eindhoven, Netherlands},
series = {TEI '16},
  selected={true},
}


@article{10.1145/2732197,
author = {de Ara\'{u}jo, B. R. and Lopes, Daniel S. and Jepp, Pauline and Jorge, Joaquim A. and Wyvill, Brian},
title = {A Survey on Implicit Surface Polygonization},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/2732197},
doi = {10.1145/2732197},
abstract = {Implicit surfaces (IS) are commonly used in image creation, modeling environments, modeling objects, and scientific data visualization. In this article, we present a survey of different techniques for fast visualization of IS. The main classes of visualization algorithms are identified along with the advantages of each in the context of the different types of IS commonly used in computer graphics. We focus closely on polygonization methods, as they are the most suited to fast visualization. Classification and comparison of existing approaches are presented using criteria extracted from current research. This enables the identification of the best strategies according to the number of specific requirements, such as speed, accuracy, quality, or stylization.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {60},
numpages = {39},
keywords = {surface rendering, surface meshing, shape modeling, polygonization, Implicit surface}
}

@article{10.1007/s11554-012-0242-0,
author = {Oliveira, Adriano and Oliveira, Jo\~{a}o F. and Pereira, Jo\~{a}o M. and De Ara\'{u}jo, Bruno R. and Boavida, Jo\~{a}o},
title = {3D modelling of laser scanned and photogrammetric data for digital documentation: the Mosteiro da Batalha case study},
year = {2014},
issue_date = {December  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {9},
number = {4},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-012-0242-0},
doi = {10.1007/s11554-012-0242-0},
abstract = {Advances in both terrestrial laser scanning hardware and photogrammetric systems combined are creating increasingly precise and rich 3D coloured data. In this article we show how computer graphics and visualization techniques have played an important role in real-time visualization, data management, modelling, and data fusion in an increasing number of applications such as surveying engineering, structure analysis, architecture, archaeology and cultural heritage. Specifically, we describe the typical modelling steps involved in the creation of a range of digital documents provided by the 3D digitization company Artescan to customers. We present how these modelling steps were applied in the context of creating digital documents used in the preservation of Mosteiro da Batalha.},
journal = {J. Real-Time Image Process.},
month = dec,
pages = {673–688},
numpages = {16},
keywords = {3D modelling, CAD, Laser scanning, Orthophoto, Photogrammetry, Virtual reality}
}

@inproceedings{10.1145/2659766.2661215,
author = {Rateau, Hana\"{e} and Grisoni, Laurent and Araujo, Bruno},
title = {Exploring tablet surrounding interaction spaces for medical imaging},
year = {2014},
isbn = {9781450328203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2659766.2661215},
doi = {10.1145/2659766.2661215},
abstract = {Medical imaging is essential to support most diagnosis. It often requires visualizing individual 2D slices from 3D volumetric datasets and switching between both representations. Combining an overview with a detailed view of the data [1] enables to keep the user in context when looking in detail at a slice. Given both their mobility and their adequacy to support direct manipulation, tablets are attractive devices to ease imaging analysis tasks. They have been successfully combined with tabletops [3], allowing new ways to explore volumetric data. However, while touch allows for a more direct manipulation, it suffers from the well-known fat fnger problem which can interfere with the display, making it hard to understand subtle visual changes. To overcome this problem, we propose to explore the space around tablet devices. Such approach has been used for displays [2] to separate several workspaces of the desktop. Here, we use such space to invoke commands that are not required to be performed on the tablet, thus maximizing the visualization space during manipulations.},
booktitle = {Proceedings of the 2nd ACM Symposium on Spatial User Interaction},
pages = {150},
numpages = {1},
keywords = {mid-air gestures, spatialized interaction, tactile interaction},
location = {Honolulu, Hawaii, USA},
series = {SUI '14}
}

@inproceedings{10.1145/2617995.2618027,
author = {Bremard, Nicolas and Grisoni, Laurent and De Araujo, Bruno},
title = {Interaction events in contactless gestural systems: from motion to interaction},
year = {2014},
isbn = {9781450328142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2617995.2618027},
doi = {10.1145/2617995.2618027},
abstract = {Contactless interactive systems appear to have an interesting context of application in interactive art, however practical example often involve low interactivity; we think this is due to the fact that this interaction paradigm is still poorly understood, and tools for interaction design are still missing. We present a simple interaction technique (Point-and-Move) that allows to point-and-click without instrument through distance; through this example, we show that the presented concept and framework has nice and flexible properties. Finally, we illustrate the approach on the two artistic installation we participated to, and also provide uncontrolled user experience feedback on the presented interaction technique, from these installations.},
booktitle = {Proceedings of the 2014 International Workshop on Movement and Computing},
pages = {166–169},
numpages = {4},
keywords = {contactless interaction, numerical art, parameterized gesture},
location = {Paris, France},
series = {MOCO '14}
}


@inproceedings{10.1145/2557500.2557545,
author = {Rateau, Hanae and Grisoni, Laurent and De Araujo, Bruno},
title = {Mimetic interaction spaces: controlling distant displays in pervasive environments},
year = {2014},
isbn = {9781450321846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2557500.2557545},
doi = {10.1145/2557500.2557545},
abstract = {Pervasive computing is a vision that has been an inspiring long-term target for many years now. Interaction techniques that allow one user to efficiently control many screens, or that allow several users to collaborate on one distant screen, are still hot topics, and are often considered as two different questions. Standard approaches require a strong coupling between the physical location of input device, and users. We propose to consider these two questions through the same basic concept, that uncouples physical location and user input, using a mid-air approach. We present the concept of mimetic interaction spaces (MIS), a dynamic user-definition of an imaginary input space thanks to an iconic gesture, that can be used to define mid-air interaction techniques. We describe a participative design user-study, that shows this technique has interesting acceptability and elicit some definition and deletion gestures. We finally describe a design space for MIS-based interaction, and show how such concept may be used for multi-screen control, as well as screen sharing in pervasive environments.},
booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
pages = {89–94},
numpages = {6},
keywords = {contactless interaction, gestural interaction, mid-air gestures},
location = {Haifa, Israel},
series = {IUI '14}
}



@inproceedings{10.1145/2512349.2512351,
author = {Daiber, Florian and De Araujo, Bruno Rodrigues and Steinicke, Frank and Stuerzlinger, Wolfgang},
title = {Interactive surfaces for interaction with stereoscopic 3d (ISIS3D): tutorial and workshop at its 2013},
year = {2013},
isbn = {9781450322713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2512349.2512351},
doi = {10.1145/2512349.2512351},
abstract = {With the increasing distribution of multi-touch capable devices multi-touch interaction becomes more and more ubiquitous. Multi-touch interaction offers new ways to deal with 3D data allowing a high degree of freedom (DOF) without instrumenting the user. Due to the advances in 3D technologies, designing for 3D interaction is now more relevant than ever. With more powerful engines and high resolution screens also mobile devices can run advanced 3D graphics, 3D UIs are emerging beyond the game industry, and recently, first prototypes as well as commercial systems bringing (auto-) stereoscopic display on touch-sensitive surfaces have been proposed. With the Tutorial and Workshop on ``Interactive Surfaces for Interaction with Stereoscopic 3D (ISIS3D)'' we aim to provide an interactive forum that focuses on the challenges that appear when the flat digital world of surface computing meets the curved, physical, 3D space we live in.},
booktitle = {Proceedings of the 2013 ACM International Conference on Interactive Tabletops and Surfaces},
pages = {483–486},
numpages = {4},
keywords = {3d user interfaces and interaction, adaptive and perception-inspired interfaces, psychophysiological studies related to stereoscopy, stereoscopic displays, touch- and gesture-based interfaces},
location = {St. Andrews, Scotland, United Kingdom},
series = {ITS '13}
}


@article{10.1016/j.cag.2012.12.005,
author = {De Ara\'{u}Jo, Bruno R. and Casiez, G\'{e}Ry and Jorge, Joaquim A. and Hachet, Martin},
title = {Special Section on Touching the 3rd Dimension: Mockup Builder: 3D modeling on and above the surface},
year = {2013},
issue_date = {May, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {3},
issn = {0097-8493},
url = {https://doi.org/10.1016/j.cag.2012.12.005},
doi = {10.1016/j.cag.2012.12.005},
abstract = {We present Mockup Builder, a semi-immersive environment for conceptual design which allows virtual mockups to be created using gestures. Our goal is to provide familiar ways for people to conceive, create and manipulate three-dimensional shapes. To this end, we developed on-and-above-the-surface interaction techniques based on asymmetric bimanual interaction for creating and editing 3D models in a stereoscopic environment. Our approach combines both hand and finger tracking in the space on and above a multi-touch surface. This combination brings forth an alternative design environment where users can seamlessly switch between interacting on the surface or above it to leverage the benefit of both interaction spaces. A formal user evaluation conducted with experienced users shows very promising avenues for further work towards providing an alternative to current user interfaces for modeling.},
journal = {Comput. Graph.},
month = may,
pages = {165–178},
numpages = {14},
keywords = {3D modeling, 3D user interface}
}


@book{10.5555/2509789,
author = {Jorge, Joaquim Armando Pires and de Araujo, Bruno Rodrigues and Soares, Luciano Pereira and Raposo, Alberto Barbosa and de Oliveira Dias, Jose Miquel and Bastos, Rafael Afonso Chiquelho Alves},
title = {Building Projection-Based VR Systems},
year = {2013},
isbn = {1568814402},
publisher = {A. K. Peters, Ltd.},
address = {USA},
edition = {1st},
abstract = {Among virtual reality technologies, a multi-projection display is certainly the most attractive and challenging. Engineers and researchersin any number of fieldsare increasingly attracted by immersive multi-projection displays. However, building a multi-projection system is a complex integration task, challenging even VR specialists. This book provides an introduction to the issues to consider when planning the installation of a multi-projection environment for researches and professionals not only in the computer graphics and virtual reality field but also in any other area that wants to use multi-projection displays. The book takes a practical approach, offering guidance in how to create a multi-projection environment. Sections: Evaluation of available display technologies Details of setting up a variety of display infrastructures Options for image generation, from cheapest to most expensive Methods for tracking users in an immersive projection environment Human-computer interaction, with an emphasis on multimodal interaction Audio: how to create a realistic auditory display in terms of sound synthesis and propagation How to utilize virtual reality software for immersive environments Case studies of VR environments the authors have constructed}
}


@inproceedings{10.5555/2305276.2305305,
author = {De Ara\`{u}jo, Bruno R. and Casiez, G\'{e}ry and Jorge, Joaquim A.},
title = {Mockup builder: direct 3D modeling on and above the surface in a continuous interaction space},
year = {2012},
isbn = {9781450314206},
publisher = {Canadian Information Processing Society},
address = {CAN},
abstract = {Our work introduces a semi-immersive environment for conceptual design where virtual mockups are obtained from gestures we aim to get closer to the way people conceive, create and manipulate three-dimensional shapes. We present on-and-above-the-surface interaction techniques following Guiard's asymmetric bimanual model to take advantage of the continuous interaction space for creating and editing 3D models in a stereoscopic environment. To allow for more expressive interactions, our approach continuously combines hand and finger tracking in the space above the table with multi-touch on its surface. This combination brings forth an alternative design environment where users can seamlessly switch between interacting on the surface or in the space above it depending on the task. Our approach integrates continuous space usage with bimanual interaction to provide an expressive set of 3D modeling operations. Preliminary trials with our experimental setup show this as a very promising avenue for further work.},
booktitle = {Proceedings of Graphics Interface 2012},
pages = {173–180},
numpages = {8},
location = {Toronto, Ontario, Canada},
series = {GI '12},
  selected={true},
}


@inproceedings{10.1109/VR.2012.6180947,
author = {Soares, Luciano P. and Jorge, Joaquim A. and Dias, Jose Miguel Salles and Raposo, Alberto and de Araujo, Bruno R. and Valbom, Leonel and Gaspar, Filipe},
title = {Title of tutorial: Designing immersive VR systems: From bits to bolts},
year = {2012},
isbn = {9781467312479},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/VR.2012.6180947},
doi = {10.1109/VR.2012.6180947},
abstract = {Immersive 3D Virtual Environments (VE) have become affordable for many research centers. However, a complete solution needs several integration steps to be fully operational. Some of these steps are difficult to accomplish and require an uncommon combination of different skills. This tutorial presents the most recent techniques developed to address this problem, from displays to software tools. The hardware in a typical VR installations combines projectors, screens, speakers, computers, tracking and I/O devices. The tutorial will discuss hardware options, explaining their advantages and disadvantages. We will cover design decisions from basic software and hardware design, through user tracking, multimodal human-computer interfaces and acoustic rendering, to how to administrate the whole solution. Additionally, we will provide an introduction to existing tracking technologies, explaining how the most common devices work, while focusing on infrared optical tracking. Finally, we briefly cover integration software and middleware developed for most VE settings.},
booktitle = {Proceedings of the 2012 IEEE Virtual Reality},
pages = {1–6},
numpages = {6},
series = {VR '12}
}


@inproceedings{10.1145/2021164.2021168,
author = {Lopes, Pedro and Mendes, Daniel and Ara\'{u}jo, Bruno and Jorge, Joaquim A.},
title = {Combining bimanual manipulation and pen-based input for 3D modelling},
year = {2011},
isbn = {9781450309066},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2021164.2021168},
doi = {10.1145/2021164.2021168},
abstract = {Multitouch enabled surfaces can bring advantages to modelling scenarios, in particular if bimanual and pen input can be combined. In this work, we assess the suitability of multitouch interfaces to 3D sketching tasks. We developed a multitouch enabled version of ShapeShop, whereby bimanual gestures allow users to explore the canvas through camera operations while using a pen to sketch. This provides a comfortable setting familiar to most users. Our contribution focuses on comparing the combined approach (bimanual and pen) to the pen-only interface for similar tasks. We conducted the evaluation helped by ten sketching experts who exercised both techniques. Results show that our approach both simplifies workflow and lowers task times, when compared to the pen-only interface, which is what most current sketching applications provide.},
booktitle = {Proceedings of the Eighth Eurographics Symposium on Sketch-Based Interfaces and Modeling},
pages = {15–22},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {SBIM '11}
}


@inproceedings{10.5555/1978005.1978224,
author = {Soares, Luciano P. and Raposo, Alberto and Jorge, Joaquim and Araujo, Bruno and Dias, Miguel and Carvalho, Felipe},
title = {Multi-projector VR Systems},
year = {2010},
isbn = {9780769542331},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Immersive multi-projection environments are becoming affordable for many research centers, but these solutions needs several integration steps to be fully operational, and some of these steps are difficult and not in a common domain. This paper presents the most recent techniques involved in multi-projection solutions, from projection to computer cluster software. The hardware in these VR (Virtual Reality) installations is a connection of projectors, screen, speaker, computers and tracking devices. This survey paper will introduce hardware options, explaining their advantages and disadvantages. We will cover software design and open source tools available, and how to administrate the whole solution.},
booktitle = {Proceedings of the 2010 23RD SIBGRAPI - Conference on Graphics, Patterns and Images Tutorials},
pages = {10–21},
numpages = {12},
keywords = {Virtual reality, Interactive computing, Computer displays},
series = {SIBGRAPI-T '10}
}

@inproceedings{10.5555/2381286.2381294,
author = {Jepp, Pauline and Araujo, Bruno and Jorge, Joaquim and Wyvill, Brian and Sousa, Mario Costa},
title = {Style nodes and repolygonization for hierarchical tree-based implicit surface modelling},
year = {2009},
isbn = {9783905674170},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {In this paper we present an extension to a hierarchical tree based implicit surface modelling system that includes interactively controlling style and appearance, and also creating a more accurate curvature based polygonal approximation. Multiple styles can be layered and applied to objects so that they are guided by local geometry although not strictly bound by it. To achieve this a new node, the Style Unary Node, is added to the ShapeShop BlobTree, which creates a style blending region inspired by primitive field blending. As visualization of implicit surfaces in interactive environments is often based on polygonization a more accurate curvature based polygonisation algorithm is also presented.},
booktitle = {Proceedings of the Fifth Eurographics Conference on Computational Aesthetics in Graphics, Visualization and Imaging},
pages = {41–48},
numpages = {8},
location = {Victoria, British Columbia, Canada},
series = {Computational Aesthetics'09}
}


@inproceedings{10.1145/1322192.1322230,
author = {Fernandes, Vitor and Guerreiro, Tiago and Ara\'{u}jo, Bruno and Jorge, Joaquim and Pereira, Jo\~{a}o},
title = {Extensible middleware framework for multimodal interfaces in distributed environments},
year = {2007},
isbn = {9781595938176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1322192.1322230},
doi = {10.1145/1322192.1322230},
abstract = {We present a framework to manage multimodal applications and interfaces in a reusable and extensible manner. We achieve this by focusing the architecture both on applications' needs and devices' capabilities. One particular domain we want to approach is collaborative environments where several modalities and applications make it necessary to provide for an extensible system combining diverse components across heterogeneous platforms on-the-fly. This paper describes the proposed framework and its main contributions in the context of an architectural application scenario. We demonstrate how to connect different non-conventional applications and input modalities around an immersive environment (tiled display wall).},
booktitle = {Proceedings of the 9th International Conference on Multimodal Interfaces},
pages = {216–219},
numpages = {4},
keywords = {reusable, multimodal interfaces, framework, extensible, collaborative, capabilitie},
location = {Nagoya, Aichi, Japan},
series = {ICMI '07}
}

@inproceedings{10.5555/1770090.1770152,
author = {Santos, Pedro and Stork, Andr\'{e} and Gierlinger, Thomas and Pagani, Alain and Ara\'{u}jo, Bruno and Jota, Ricardo and Bruno, Luis and Jorge, Joaquim and Pereira, Joao Madeiras and Witzel, Martin and Conti, Giuseppe and Amicis, Raffaele de and Barandarian, I\~{n}igo and Paloc, C\'{e} line and Machui, Oliver and Jim\'{e} nez, Jose M and Bodammer, Georg and McIntyre, Don},
title = {IMPROVE: collaborative design review in mobile mixed reality},
year = {2007},
isbn = {9783540733348},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we introduce an innovative application designed tomake collaborative design review in the architectural and automotive domainmore effective. For this purpose we present a system architecture whichcombines variety of visualization displays such as high resolution multitile displays, TabletPCs and head-mounted displays with innovative 2D and 3DInteraction Paradigms to better support collaborative mobile mixed realitydesign reviews. Our research and development is motivated by two usescenarios: automotive and architectural design review involving real users fromPagePark architects and FIAT Elasis. Our activities are supported by the EUIST project IMPROVE aimed at developing advanced display techniques,fostering activities in the areas of: optical see-through HMD development usingunique OLED technology, marker-less optical tracking, mixed reality rendering,image calibration for large tiled displays, collaborative tablet-based andprojection wall oriented interaction and stereoscopic video streaming for mobileusers. The paper gives an overview of the hardware and software developmentswithin IMPROVE and concludes with results from first user tests.},
booktitle = {Proceedings of the 2nd International Conference on Virtual Reality},
pages = {543–553},
numpages = {11},
location = {Beijing, China},
series = {ICVR'07}
}

@inproceedings{10.5555/1770090.1770133,
author = {Santos, Pedro and Stork, Andr\'{e} and Gierlinger, Thomas and Pagani, Alain and Ara\'{u}jo, Bruno and Jota, Ricardo and Bruno, Luis and Jorge, Joaquim and Pereira, Joao Madeiras and Witzel, Martin and Conti, Giuseppe and de Amicis, Raffaele and Barandarian, I\~{n}igo and Paloc, C\'{e}line and Hafner, Maylu and McIntyre, Don},
title = {IMPROVE: advanced displays and interaction techniques for collaborative design review},
year = {2007},
isbn = {9783540733348},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we present evaluation results of an innovative application designed to make collaborative design review in the architectural and automotive domain more effective. Within IMPROVE, a European research project in the area of advanced displays, we are combining high resolution multi-tile displays, TabletPCs and head-mounted displays with innovative 2D and 3D Interaction Paradigms to better support collaborative mobile mixed reality design reviews. Our research and development is motivated by application scenarios in the automotive domain involving FIAT Elasis from Naples, Italy and in the architectural domain involving Page/Park architects from Glasgow, Scotland. User evaluation took place at Glasgow (UK), Naples (ITA) and Darmstadt (GER), where we tested the integrated IMPROVE prototype application. The tests were conducted based on several heuristics such as ergonomics and psychomotorial factors and they were conducted based on guidelines recommended by ISO 9241 to verify whether the developed interfaces were suitable for the applications scenarios. Evaluation results show that there is a strong demand for more interactive design review systems, allowing users greater flexibility and greater choice of input and visualization modalities as well as their combination.},
booktitle = {Proceedings of the 2nd International Conference on Virtual Reality},
pages = {376–385},
numpages = {10},
location = {Beijing, China},
series = {ICVR'07}
}


@inproceedings{10.5555/1757268.1757348,
author = {Santos, Pedro and Stork, Andr\'{e} and Gierlinger, Thomas and Pagani, Alain and Ara\'{u}jo, Bruno and Jota, Ricardo and Bruno, Luis and Jorge, Joaquim and Pereira, Joao Madeiras and Witzel, Martin and Conti, Giuseppe and De Amicis, Raffaele and Barandarian, I\~{n}igo and Paloc, C\'{e}line and Hafner, Maylu and McIntyre, Don},
title = {IMPROVE: designing effective interaction for virtual and mixed reality environments},
year = {2007},
isbn = {9783540731061},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In this paper we present evaluation results of an innovative application designed to make collaborative design review in the architectural and automotive domain more effective. Within IMPROVE, a European research project in the area of advanced displays, we are combining high resolution multi-tile displays, TabletPCs and head-mounted displays with innovative 2D and 3D Interaction Paradigms to better support collaborative mobile mixed reality design reviews. Our research and development is motivated by application scenarios in the automotive domain involving FIAT Elasis from Naples, Italy and in the architectural domain involving Page/Park architects from Glasgow, Scotland. User evaluation took place at Glasgow (UK), Naples (ITA) and Darmstadt (GER), where we tested the integrated IMPROVE prototype application. The tests were conducted based on several heuristics such as ergonomics and psychomotorial factors and they were conducted based on guidelines recommended by ISO 9241 to verify whether the developed interfaces were suitable for the applications scenarios. Evaluation results show that there is a strong demand for more interactive design review systems, allowing users greater flexibility and greater choice of input and visualization modalities as well as their combination.},
booktitle = {Proceedings of the 12th International Conference on Human-Computer Interaction: Interaction Platforms and Techniques},
pages = {689–699},
numpages = {11},
location = {Beijing, China},
series = {HCI'07}
}

@inproceedings{10.1109/SIBGRAPI.2005.2,
author = {De Araujo, Bruno Rodrigues and Jorge, Joaquim Armando Pires},
title = {A Calligraphic Interface for Interactive Free-Form Modeling with Large Datasets},
year = {2005},
isbn = {0769523897},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SIBGRAPI.2005.2},
doi = {10.1109/SIBGRAPI.2005.2},
abstract = {We present a sketching interface for modeling shapes definedby large sets of points. Our system supports powerful modeling operations that are applied directly to the points defining the surface. These operations are based on sketch input to allow directly creating objects using simple strokes. Objects may be edited by either by boundary over-sketching, or by cutting, relief drawing on surfaces, merging and cloning. By combining these operations we can create complex shapes, including objects with sharp features. Our work uses the Multi-level Partition of Unity Implicits (MPU) technique to convert point clouds into implicit surfaces. Furthermore, we have devised a fast adaptive incremental polygonization algorithm which takes advantage of the MPU structure. This makes local re-polygonization possible and allows real-time modifications to large point sets since it avoids re-calculating the whole polygonal representation from scratch after each modification.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Computer Graphics and Image Processing},
pages = {333},
series = {SIBGRAPI '05}
}

@article{10.1016/j.cag.2005.08.027,
author = {Rodrigues de Ara\'{u}jo, Bruno and Armando Pires Jorge, Joaquim},
title = {Adaptive polygonization of implicit surfaces},
year = {2005},
issue_date = {October, 2005},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {29},
number = {5},
issn = {0097-8493},
url = {https://doi.org/10.1016/j.cag.2005.08.027},
doi = {10.1016/j.cag.2005.08.027},
abstract = {We present an algorithm for polygonizing closed implicit surfaces, which produces meshes adapted to the local curvature of the surface. Our method is similar to, but not based on, Marching Triangles, in that we start from a point on the surface and develop a mesh from that point using a surface-tracking approach. However, our approach works by managing fronts, or sets of points on the border of the current polygonization. Fronts can subdivide to form new fronts or merge if they become adjacent. In a marked departure from previous approaches, our meshes approximate the surface through heuristics relying on curvature. Furthermore, our method works completely on-the-fly, resolving cracks as it proceeds, without the need for any post-remeshing step to correct failures. We have tested the algorithm with three different representations of implicit surfaces, variational, analytical and MPU, using non-trivial data sets, yielding results that illustrate the flexibility and scalability of our technique. Performance comparisons with variants of Marching Cubes show that our approach is capable of good accuracy and meshing quality without sacrificing computing resources.},
journal = {Comput. Graph.},
month = oct,
pages = {686–696},
numpages = {11},
keywords = {Adaptive meshing, Implicit curvature, Implicit surfaces, Polygonization}
}

@inproceedings{10.5555/1025131.1026262,
author = {Araujo, Bruno Rodrigues de and Jorge, Joaquim Armando Pires},
title = {Curvature Dependent Polygonization of Implicit Surfaces},
year = {2004},
isbn = {0769522270},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We present an algorithm for polygonizing closed implicit surfaces, which produces meshes adapted to the local curvature of the surface.Our method is similar to, but NOT based on, Marching Triangles, in that we start from a point on the surface and develop a mesh from that point using a surface-tracking approach.In a marked departure from previous approaches, our meshes approximate the surface through heuristics relying on curvature.Furthermore, our method works completely on-the-fly, resolving cracks as it proceeds, without the need for any post-remeshing step to correct failures.We have tested the algorithm with three different representations of implicit surfaces, Variational, analytical and MPU, using non-trivial data sets, yielding results that illustrate the flexibility and scalability of our technique.Performance comparisons with variants of Marching Cubes show that our approach is capable of good accuracy and meshing quality without sacrificing computing resources.},
booktitle = {Proceedings of the Computer Graphics and Image Processing, XVII Brazilian Symposium},
pages = {266–273},
numpages = {8},
series = {SIBGRAPI '04}
}


@inproceedings{10.1145/1186415.1186542,
author = {de Ara\'{u}jo, Bruno and Jorge, Joaquim and Sousa, Mario Costa and Samavati, Faramarz and Wyvill, Brian},
title = {MIBlob: a tool for medical visualization and modelling using sketches},
year = {2004},
isbn = {1581138962},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1186415.1186542},
doi = {10.1145/1186415.1186542},
booktitle = {ACM SIGGRAPH 2004 Posters},
pages = {107},
location = {Los Angeles, California},
series = {SIGGRAPH '04}
}